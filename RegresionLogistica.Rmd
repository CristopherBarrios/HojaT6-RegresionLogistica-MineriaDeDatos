---
title: "RegresionLogistica"
author: "Cristopher Barrios, Carlos Daniel Estrada"
date: "2023-04-14"
output:
  pdf_document: default
  html_document: default
---

```{r}
#Librerias
library(dplyr)
glimpse(mtcars)
library(tidyr)
library(rpart)
library(caret)
library(tree)
library(rpart.plot)
library(randomForest)
library(dplyr)
library(tidyr)
library(cluster)
library(e1071)
library(mclust)
library(fpc)
library(NbClust)
library(factoextra)
library(cluster)
library(e1071)
library(mclust)
library(fpc)
library(NbClust)
library(factoextra)
library(rpart)
library(corrplot)
library(dummies) #install.packages("C:/Users/cjrba/Downloads/dummies_1.5.6.tar.gz", repos = NULL, type = "source")
library(fastDummies)
library(PerformanceAnalytics)
library(tictoc)
```
### 1. Cree una variable dicotómica por cada una de las categorías de la variable respuesta categórica que creó en hojas anteriores. Debería tener 3 variables dicotómicas (valores 0 y 1) una que diga si la vivienda es cara o no, media o no, económica o no.
```{r}

train<- read.csv("train.csv", stringsAsFactors = FALSE)
test<- read.csv("test.csv", stringsAsFactors = FALSE)
train<-train[1:1460,]
glimpse(train[1:10,])

porcentaje<-0.7
datos<-read.csv("train.csv", stringsAsFactors = FALSE)
set.seed(123)
corte <- sample(nrow(datos),nrow(datos)*porcentaje)
train<-datos[corte,]
test<-datos[-corte,]


head(train)


head(test)
glimpse(train[1:10,])
scatter.smooth(train$LotFrontage, train$SalePrice)
scatter.smooth(train$LotArea, train$SalePrice)
scatter.smooth(train$GrLivArea, train$SalePrice)
scatter.smooth(train$YearBuilt, train$SalePrice)
scatter.smooth(train$BsmtUnfSF, train$SalePrice)
scatter.smooth(train$TotalBsmtSF, train$SalePrice)
scatter.smooth(train$X1stFlrSF, train$SalePrice)
scatter.smooth(train$GarageYrBlt, train$SalePrice)
scatter.smooth(train$GarageArea, train$SalePrice)
scatter.smooth(train$YearRemodAdd, train$SalePrice)
scatter.smooth(train$TotRmsAbvGrd, train$SalePrice)
scatter.smooth(train$MoSold, train$SalePrice)
scatter.smooth(train$OverallQual, train$SalePrice)

#variables dicotomicas
datos$grupo <- ifelse(datos$SalePrice<178000, "3", 
                      ifelse(datos$SalePrice<301000, "2",
                             ifelse(datos$SalePrice<756000,"1",NA)))
datos$grupo2 <- ifelse(datos$SalePrice<178000, "3", 
                      ifelse(datos$SalePrice<301000, "2",NA))
datos$grupo3 <- ifelse(datos$SalePrice<178000, "3", NA)
datos$grupo <- as.factor(datos$grupo)
datos$grupo2 <- as.factor(datos$grupo2)
datos$grupo3 <- as.factor(datos$grupo3)
datos<-cbind(datos,dummy(datos$grupo,verbose = T),dummy(datos$grupo2,verbose = T), dummy(datos$grupo3,verbose = T))
datos <- datos[,c("LotFrontage","LotArea","GrLivArea","YearBuilt","BsmtUnfSF","TotalBsmtSF","X1stFlrSF","GarageYrBlt","GarageArea","YearRemodAdd", "SalePrice", "datos1","datos2","datos3")]
datos <- na.omit(datos)
head(datos, 30)
porcentaje<-0.7
corte <- sample(nrow(datos),nrow(datos)*porcentaje)
train<-datos[corte,]
test<-datos[-corte,]
head(train)
head(test)
```

### 2. Use los mismos conjuntos de entrenamiento y prueba que utilizó en las hojas anteriores.
```{r}
tic("Entrenamiento modelo casas caras")
startm1 <- Sys.time()
modelo<-glm(datos1~., data = train[,c(2:10,12)],family = binomial(), maxit=100)
modelo
finalm1 <- Sys.time()
totalTm1 <- finalm1 - startm1
toc()

```

```{r}
tic("Entrenamiento modelo casas intermedias")
startm2 <- Sys.time()
modelo2<-glm(datos2~., data = train[,c(2:10,13)],family = binomial(), maxit=100)
modelo2
finalm2 <- Sys.time()
totalTm2 <- finalm2 - startm2
toc()

```

```{r}
tic("Entrenamiento modelo casas baratas")
startm3 <- Sys.time()
modelo3<-glm(datos3~., data = train[,c(2:10,14)],family = binomial(), maxit=100)
modelo3
finalm3 <- Sys.time()
totalTm3 <- finalm3 - startm3
toc()
```
En este caso se pueden ver los conjuntos de entrenamiento de casas caras, intermedias y baratas

### 3. Elabore un modelo de regresión logística para conocer si una vivienda es cara o no, utilizando el conjunto de entrenamiento y explique los resultados a los que llega. El experimento debe ser reproducible por lo que debe fijar que los conjuntos de entrenamiento y prueba sean los mismos siempre que se ejecute el código. Use validación cruzada.
```{r}

ggplot(data = train[,c("GrLivArea","datos1")], aes(x = GrLivArea, y = datos1)) +
  geom_point(aes(color = as.factor(datos1)), shape = 1) + 
  geom_smooth(method = "glm",
              method.args = list(family = "binomial"),
              color = "pink",
              se = FALSE) +
  theme_bw() +
  labs(title = "Regresion logistica: Casas Caras",
       y = "Probabilidad default") +
  theme(legend.position = "none")

```

```{r}
ggplot(data = train[,c("GrLivArea","datos2")], aes(x = GrLivArea, y = datos2)) +
  geom_point(aes(color = as.factor(datos2)), shape = 1) + 
  geom_smooth(method = "glm",
              method.args = list(family = "binomial"),
              color = "pink",
              se = FALSE) +
  theme_bw() +
  labs(title = "Regresion logistica: Casas Intermedias",
       y = "Probabilidad default") +
  theme(legend.position = "none")
```

```{r}
ggplot(data = train[,c("GrLivArea","datos3")], aes(x = GrLivArea, y = datos3)) +
  geom_point(aes(color = as.factor(datos3)), shape = 1) + 
  geom_smooth(method = "glm",
              method.args = list(family = "binomial"),
              color = "pink",
              se = FALSE) +
  theme_bw() +
  labs(title = "Regresion logistica: Casas Economicas",
       y = "Probabilidad default") +
  theme(legend.position = "none")
```

Se están creando tres gráficas de regresión logística utilizando el paquete ggplot. Cada gráfica muestra la relación entre la variable GrLivArea y una variable objetivo de clasificación llamada "datos1", "datos2" y "datos3" respectivamente.

Cada gráfica tiene puntos de datos que representan la variable GrLivArea en el eje x y la variable objetivo en el eje y, con diferentes colores para indicar la clasificación. Además, cada gráfica incluye una línea de regresión logística ajustada utilizando el método glm con argumentos de familia binomial, y se utiliza el color rosa para resaltar la línea.


### 4. Analice el modelo. Determine si hay multicolinealidad en las variables, y cuáles son las que aportan al modelo, por su valor de significación. Haga un análisis de correlación de las variables del modelo y especifique si el modelo se adapta bien a los datos.
```{r warning=FALSE, unload=TRUE}

dat1 <- data.frame(datos[,c("LotFrontage","LotArea","GrLivArea","YearBuilt","BsmtUnfSF","TotalBsmtSF","X1stFlrSF","GarageYrBlt","GarageArea","YearRemodAdd", "SalePrice")])
chart.Correlation(dat1)
```
La observación de la tabla de correlación revela la existencia de variables que presentan altos índices de correlación, lo que indica que estas variables son relevantes para el modelo de regresión lineal y pueden ser útiles para predecir el valor de la variable dependiente. Asimismo, la presencia de estas variables con altos índices de correlación sugiere que el modelo de regresión lineal se ajusta bien a los datos asociados con estas variables.

### 5. Utilice el modelo con el conjunto de prueba y determine la eficiencia del algoritmo para clasificar.
```{r}
prediction1 <- predict(modelo, test)
prediction1

```

```{r}
prediction2 <- predict(modelo2, test)
prediction2

```

```{r}
prediction3 <- predict(modelo3, test)
prediction3
```
Se puede observar el resultado de las variables de respuesta a través de la predicción realizada.

### 6. Explique si hay sobreajuste (overfitting) o no (recuerde usar para esto los errores del conjunto de prueba y de entrenamiento). Muestre las curvas de aprendizaje usando los errores de los conjuntos de entrenamiento y prueba.

```{r}

```
Cuando se presenta el fenómeno del sobreajuste (overfitting), es posible que esto se deba a que ciertas variables, en particular aquellas que tienen una correlación baja entre sí, estén influyendo demasiado en el modelo.

### 7. Haga otros dos modelos cambiando las variables predictoras de acuerdo con la significación de los coeficientes en el primer modelo. Explique por qué seleccionó las variables que uso para cada modelo.

### 8. Haga un análisis de la eficiencia del algoritmo usando una matriz de confusión. Tenga en cuenta la efectividad, donde el algoritmo se equivocó más, donde se equivocó menos y la importancia que tienen los errores, el tiempo y la memoria consumida. Para esto último puede usar “profvis” si trabaja con R y “cProfile” en Python.
```{r}
#Matriz de confusión
library(caret)
#table(factor(prediction, levels=min(test):max(test)), factor(test, levels=min(test):max(test)))
#cfm <- confusionMatrix(prediction,as.factor(test$datos1))
#cfm
```

```{r}
print("Tiempo de entrenamiento modelo casas caras: ")
totalTm1
```

```{r}
print("Tiempo de entrenamiento modelo casas intermedias: ")
totalTm2
```
```{r}
print("Tiempo de entrenamiento modelo casas baratas: ")
totalTm3
```

### 9. Determine cual de todos los modelos es mejor, puede usar AIC y BIC para esto, además de los parámetros de la matriz de confusión y los del profiler.
```{r}
AICmodelo <- AIC(modelo)
BICmodelo <- BIC(modelo)

print("Modelo 1 AIC: ")
AICmodelo
print("Modelo 1 BIC: ")
BICmodelo
```

```{r}
AICmodelo2 <- AIC(modelo2)
BICmodelo2 <- BIC(modelo2)

print("Modelo 2 AIC: ")
AICmodelo2
print("Modelo 2 BIC: ")
BICmodelo2
```

```{r}
AICmodelo3 <- AIC(modelo3)
BICmodelo3 <- BIC(modelo3)

print("Modelo 3 AIC: ")
AICmodelo3
print("Modelo 3 BIC: ")
BICmodelo3
```
Después de realizar el análisis utilizando AIC y BIC, se puede concluir que el Modelo 1 es el mejor modelo ya que tiene el menor valor de AIC y BIC. En este caso se recomienda utilizar el Modelo 1 para predecir y clasificar los datos.

### 10. Haga un modelo de árbol de decisión, uno de Random Forest y uno de Naive Bayes usando la misma variable respuesta y los mismos predictores que el mejor de los modelos de Regresión Logística.

### 11. Compare la eficiencia de los 3 modelos que creó en el punto anterior y el mejor de los de regresión logística ¿Cuál se demoró más en procesar?¿Cuál se equivocó más?¿Cuál se equivocó menos?¿por qué?
